{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Building Semantic Memory with Embeddings\n",
    "\n",
    "So far, we've mostly been treating the kernel as a stateless orchestration engine.\n",
    "We send text into a model API and receive text out. \n",
    "\n",
    "In a [previous notebook](04-context-variables-chat.ipynb), we used `context variables` to pass in additional\n",
    "text into prompts to enrich them with more context. This allowed us to create a basic chat experience. \n",
    "\n",
    "However, if you solely relied on context variables, you would quickly realize that eventually your prompt\n",
    "would grow so large that you would run into the model's token limit. What we need is a way to persist state\n",
    "and build both short-term and long-term memory to empower even more intelligent applications. \n",
    "\n",
    "To do this, we dive into the key concept of `Semantic Memory` in the Semantic Kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install semantic-kernel==0.4.5.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60399ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    OpenAIChatCompletion,\n",
    "    OpenAITextEmbedding,\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "deployment_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "embeddings = os.environ[\"OPENAI_EMBEDDINGS_MODEL_NAME\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ddffc1",
   "metadata": {},
   "source": [
    "In order to use memory, we need to instantiate the Kernel with a Memory Storage\n",
    "and an Embedding service. In this example, we make use of the `VolatileMemoryStore` which can be thought of as a temporary in-memory storage. This memory is not written to disk and is only available during the app session.\n",
    "\n",
    "When developing your app you will have the option to plug in persistent storage like Azure AI Search, Azure Cosmos Db, PostgreSQL, SQLite, etc. Semantic Memory allows also to index external data sources, without duplicating all the information as you will see further down in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8dcbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': SKFunction(), 'save': SKFunction()}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    # next line assumes chat deployment name is \"turbo\", adjust the deployment name to the value of your chat model if needed\n",
    "    azure_chat_service = AzureChatCompletion(deployment_name=deployment_name, endpoint=endpoint, api_key=key)\n",
    "    # next line assumes embeddings deployment name is \"text-embedding\", adjust the deployment name to the value of your chat model if needed\n",
    "    azure_text_embedding = AzureTextEmbedding(deployment_name=embeddings, endpoint=endpoint, api_key=key)\n",
    "    kernel.add_chat_service(\"chat_completion\", azure_chat_service)\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", azure_text_embedding)\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    oai_chat_service = OpenAIChatCompletion(ai_model_id=\"gpt-3.5-turbo\", api_key=api_key, org_id=org_id)\n",
    "    oai_text_embedding = OpenAITextEmbedding(ai_model_id=\"text-embedding-ada-002\", api_key=api_key, org_id=org_id)\n",
    "    kernel.add_chat_service(\"chat-gpt\", oai_chat_service)\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", oai_text_embedding)\n",
    "\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7fefb6a",
   "metadata": {},
   "source": [
    "At its core, Semantic Memory is a set of data structures that allow you to store the meaning of text that come from different data sources, and optionally to store the source text too. These texts can be from the web, e-mail providers, chats, a database, or from your local directory, and are hooked up to the Semantic Kernel through data source connectors.\n",
    "\n",
    "The texts are embedded or compressed into a vector of floats representing mathematically the texts' contents and meaning. You can read more about embeddings [here](https://aka.ms/sk/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea1a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cognitive_search import (\n",
    "    AzureCognitiveSearchMemoryStore,\n",
    ")\n",
    "\n",
    "azure_ai_search_api_key, azure_ai_search_url = sk.azure_aisearch_settings_from_dot_env()\n",
    "\n",
    "# text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    "kernel.register_memory_store(\n",
    "    memory_store=AzureCognitiveSearchMemoryStore(\n",
    "        vector_size=1536,\n",
    "        search_endpoint=azure_ai_search_url,\n",
    "        admin_key=azure_ai_search_api_key,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb4c818d",
   "metadata": {},
   "source": [
    "**Ojo error:**\n",
    "\n",
    "HttpResponseError: () Invalid expression: Could not find a property named 'Text' on type 'search.document'.\n",
    "Parameter name: $select\n",
    "\n",
    "return MemoryQueryResult(\n",
    "            is_reference=record._is_reference,\n",
    "            external_source_name=record._external_source_name,\n",
    "            id=record._id,\n",
    "            description=record._description,\n",
    "            text=record._text,\n",
    "            additional_metadata=record._additional_metadata,\n",
    "            embedding=record._embedding,\n",
    "            relevance=relevance,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b19d357",
   "metadata": {},
   "source": [
    "index = os.environ[\"AZURE_AISEARCH_INDEX_NAME\"]\n",
    "question = 'What is the Revenue of Microsoft?'\n",
    "result = await kernel.memory.search_async(index, question, limit=5, min_relevance_score=0.77)\n",
    "print(\"===========================\\n\" + \"Query: \" + question + \"\\n\")\n",
    "print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687b34f",
   "metadata": {},
   "source": [
    "# Issue activo en semantic-kernel discord forum\n",
    "https://discord.com/channels/1063152441819942922/1098714016890769408/1194920438384570378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e1091d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cognitive Search Service header settings\n",
    "HEADERS = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': os.environ[\"AZURE_AISEARCH_API_KEY\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac527c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_documents(question):\n",
    "    \"\"\"Search documents using Azure Cognitive Search\"\"\"\n",
    "    # Construct the Azure Cognitive Search service access URL\n",
    "    url = (SEARCH_SERVICE_ENDPOINT + 'indexes/' +\n",
    "               SEARCH_SERVICE_INDEX_NAME1 + '/docs')\n",
    "    # Create a parameter dictionary\n",
    "    params = {\n",
    "        'api-version': SEARCH_SERVICE_API_VERSION,\n",
    "        'search': question,\n",
    "        'select': '*',\n",
    "        # '$top': 3, Extract the top 3 documents from your storage. (If you have a lot of documents, you can increase this value).\n",
    "        '$top': 3,\n",
    "        'queryLanguage': 'en-us',\n",
    "        'queryType': 'semantic',\n",
    "        'semanticConfiguration': SEARCH_SERVICE_SEMANTIC_CONFIG_NAME,\n",
    "        '$count': 'true',\n",
    "        'speller': 'lexicon',\n",
    "        'answers': 'extractive|count-3',\n",
    "        'captions': 'extractive|highlight-false'\n",
    "        }\n",
    "    # Make a GET request to the Azure Cognitive Search service and store the response in a variable\n",
    "    resp = requests.get(url, headers=HEADERS, params=params)\n",
    "    # Return the JSON response containing the search results\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e70643cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "62aa66cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
