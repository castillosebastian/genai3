{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Building Semantic Search with Memory: a problem!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install semantic-kernel==0.4.5.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508ad44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import os\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    OpenAIChatCompletion,\n",
    "    OpenAITextEmbedding,\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "deployment_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "embeddings = os.environ[\"OPENAI_EMBEDDINGS_MODEL_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8dcbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': SKFunction(), 'save': SKFunction()}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    # next line assumes chat deployment name is \"turbo\", adjust the deployment name to the value of your chat model if needed\n",
    "    azure_chat_service = AzureChatCompletion(deployment_name=deployment_name, endpoint=endpoint, api_key=key)\n",
    "    # next line assumes embeddings deployment name is \"text-embedding\", adjust the deployment name to the value of your chat model if needed\n",
    "    azure_text_embedding = AzureTextEmbedding(deployment_name=embeddings, endpoint=endpoint, api_key=key)\n",
    "    kernel.add_chat_service(\"chat_completion\", azure_chat_service)\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", azure_text_embedding)\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    oai_chat_service = OpenAIChatCompletion(ai_model_id=\"gpt-3.5-turbo\", api_key=api_key, org_id=org_id)\n",
    "    oai_text_embedding = OpenAITextEmbedding(ai_model_id=\"text-embedding-ada-002\", api_key=api_key, org_id=org_id)\n",
    "    kernel.add_chat_service(\"chat-gpt\", oai_chat_service)\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", oai_text_embedding)\n",
    "\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7fefb6a",
   "metadata": {},
   "source": [
    "At its core, Semantic Memory is a set of data structures that allow you to store the meaning of text that come from different data sources, and optionally to store the source text too. These texts can be from the web, e-mail providers, chats, a database, or from your local directory, and are hooked up to the Semantic Kernel through data source connectors.\n",
    "\n",
    "The texts are embedded or compressed into a vector of floats representing mathematically the texts' contents and meaning. You can read more about embeddings [here](https://aka.ms/sk/embeddings)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59294dac",
   "metadata": {},
   "source": [
    "Now you might be wondering what happens if you have so much data that it doesn't fit into your RAM? That's where you want to make use of an external Vector Database made specifically for storing and retrieving embeddings. Fortunately, semantic kernel makes this easy thanks to an extensive list of available connectors. In the following section, we will connect to an existing Azure AI Search service that we will use as an external Vector Database to store and retrieve embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae148b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cognitive_search import (\n",
    "    AzureCognitiveSearchMemoryStore,\n",
    ")\n",
    "\n",
    "azure_ai_search_api_key, azure_ai_search_url = sk.azure_aisearch_settings_from_dot_env()\n",
    "\n",
    "# text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    "kernel.register_memory_store(\n",
    "    memory_store=AzureCognitiveSearchMemoryStore(\n",
    "        vector_size=1536,\n",
    "        search_endpoint=azure_ai_search_url,\n",
    "        admin_key=azure_ai_search_api_key,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6122f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "() Invalid expression: Could not find a property named 'Id' on type 'search.document'.\r\nParameter name: $select\nCode: \nMessage: Invalid expression: Could not find a property named 'Id' on type 'search.document'.\r\nParameter name: $select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m index \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_AISEARCH_INDEX_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhat is the Revenue of Microsoft?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m kernel\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msearch_async(index, question)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/semantic_kernel/memory/semantic_text_memory.py:143\u001b[0m, in \u001b[0;36mSemanticTextMemory.search_async\u001b[0;34m(self, collection, query, limit, min_relevance_score, with_embeddings)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search the memory (calls the memory store's get_nearest_matches method).\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    List[MemoryQueryResult] -- The list of MemoryQueryResult found.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embeddings_generator\u001b[38;5;241m.\u001b[39mgenerate_embeddings_async([query]))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 143\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mget_nearest_matches_async(\n\u001b[1;32m    144\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection,\n\u001b[1;32m    145\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mquery_embedding,\n\u001b[1;32m    146\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m    147\u001b[0m     min_relevance_score\u001b[38;5;241m=\u001b[39mmin_relevance_score,\n\u001b[1;32m    148\u001b[0m     with_embeddings\u001b[38;5;241m=\u001b[39mwith_embeddings,\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [MemoryQueryResult\u001b[38;5;241m.\u001b[39mfrom_memory_record(r[\u001b[38;5;241m0\u001b[39m], r[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/semantic_kernel/connectors/memory/azure_cognitive_search/azure_cognitive_search_memory_store.py:402\u001b[0m, in \u001b[0;36mAzureCognitiveSearchMemoryStore.get_nearest_matches_async\u001b[0;34m(self, collection_name, embedding, limit, min_relevance_score, with_embeddings)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# Convert the results to MemoryRecords\u001b[39;00m\n\u001b[1;32m    401\u001b[0m nearest_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m search_record \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m search_record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@search.score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m min_relevance_score:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/azure/search/documents/aio/_paging.py:26\u001b[0m, in \u001b[0;36mAsyncSearchItemPaged.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mby_page()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_page_iterator_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Let it raise StopAsyncIteration\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/azure/search/documents/aio/_paging.py:29\u001b[0m, in \u001b[0;36mAsyncSearchItemPaged.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Let it raise StopAsyncIteration\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/azure/core/async_paging.py:94\u001b[0m, in \u001b[0;36mAsyncPageIterator.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of paging\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuation_token)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/azure/search/documents/aio/_paging.py:106\u001b[0m, in \u001b[0;36mAsyncSearchPageIterator._get_next_cb\u001b[0;34m(self, continuation_token)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_next_cb\u001b[39m(\u001b[38;5;28mself\u001b[39m, continuation_token):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continuation_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39msearch_post(search_request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_query\u001b[38;5;241m.\u001b[39mrequest, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[1;32m    108\u001b[0m     _next_link, next_page_request \u001b[38;5;241m=\u001b[39m unpack_continuation_token(continuation_token)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39msearch_post(search_request\u001b[38;5;241m=\u001b[39mnext_page_request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/azure/core/tracing/decorator_async.py:77\u001b[0m, in \u001b[0;36mdistributed_trace_async.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/azure/search/documents/_generated/aio/operations/_documents_operations.py:421\u001b[0m, in \u001b[0;36mDocumentsOperations.search_post\u001b[0;34m(self, search_request, request_options, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    420\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mSearchError, pipeline_response)\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n\u001b[1;32m    423\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearchDocumentsResult\u001b[39m\u001b[38;5;124m\"\u001b[39m, pipeline_response)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: () Invalid expression: Could not find a property named 'Id' on type 'search.document'.\r\nParameter name: $select\nCode: \nMessage: Invalid expression: Could not find a property named 'Id' on type 'search.document'.\r\nParameter name: $select"
     ]
    }
   ],
   "source": [
    "index = os.environ[\"AZURE_AISEARCH_INDEX_NAME\"]\n",
    "question = 'what is the Revenue of Microsoft?'\n",
    "result = await kernel.memory.search_async(index, question)\n",
    "print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838208e",
   "metadata": {},
   "source": [
    "# Dónde está el problema: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acdbd03",
   "metadata": {},
   "source": [
    "En el detalle precedente están las distintas llamadas a las funciones que generan el error. \n",
    "\n",
    "> Esta llamada: `File ~/.cache/pypoetry/virtualenvs/semantic-kernel-lHv8C67X-py3.9/lib/python3.9/site-packages/semantic_kernel/memory/semantic_text_memory.py:143, in SemanticTextMemory.search_async(self, collection, query, limit, min_relevance_score, with_embeddings)\n",
    "    130 \"\"\"Search the memory (calls the memory store's get_nearest_matches method).`\n",
    "\n",
    "La clase `memory` contiene un método que se denomina `search_async` cuyo resultado debe tener la estructura siguiente:\n",
    "\n",
    "\n",
    "```\n",
    "return MemoryQueryResult(\n",
    "            is_reference=record._is_reference,\n",
    "            external_source_name=record._external_source_name,\n",
    "            id=record._id,\n",
    "            description=record._description,\n",
    "            text=record._text,\n",
    "            additional_metadata=record._additional_metadata,\n",
    "            embedding=record._embedding,\n",
    "            relevance=relevance,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78532ef8",
   "metadata": {},
   "source": [
    "# En este foro de semantic-kernel está tratado  este problema en .NET y dice:\n",
    "\n",
    "### https://discord.com/channels/1063152441819942922/1098714016890769408/1194920438384570378   \n",
    "\n",
    "Richard Urwin — 11/01/2024 5:27\n",
    "Hi all,\n",
    "     \n",
    " I've got a pre-existing ingestion pipeline, indexing content (with embeddings) into Azure AI search, so I don't need the indexing functionality provided by KernelMemory (server or serverless).\n",
    "     \n",
    " I want to use KernelMemory as part of a RAG process, but the stumbling block seems to be that the field names in my index must match those hardcoded in the AzureAISearchMemoryRecord because there appears to be no way of overriding them (the class is sealed, the values are constants, it doesn't implement an interface, etc.). There's even a comment to this end:\n",
    "     \n",
    "```\n",
    "namespace Microsoft.KernelMemory.MemoryDb.AzureAISearch;\n",
    "     \n",
    "// TODO: support bring your own index schema\n",
    "public sealed class AzureAISearchMemoryRecord\n",
    "{\n",
    "    internal const string IdField = \"id\";\n",
    "    internal const string VectorField = \"embedding\";\n",
    "    private const string TagsField = \"tags\";\n",
    "    private const string PayloadField = \"payload\";\n",
    "...\n",
    "}\n",
    "``` \n",
    "\n",
    "The files in question are:\n",
    "- https://github.com/microsoft/kernel-memory/blob/4b92c2896eb14dc4f948c792937238057a694838/extensions/AzureAISearch/AzureAISearch/AzureAISearchMemoryRecord.cs#L14\n",
    "- https://github.com/microsoft/kernel-memory/blob/4b92c2896eb14dc4f948c792937238057a694838/extensions/AzureAISearch/AzureAISearch/AzureAISearchMemoryRecord.cs#L14\n",
    "\n",
    "Any suggestions as to how to work around this, other than taking a copy of AzureAISearchMemory.cs and AzureAISearchMemoryRecord.cs, modifying them as required and then the former  in the KernelMemoryBuilder using WithCustomMemoryDb(...)?\n",
    "    \n",
    "Thanks,\n",
    "Rich\n",
    "\n",
    "---\n",
    "\n",
    "La solución estaría implementada en .NET pero no disponible aún: \n",
    "\n",
    "Devis Lucato\n",
    "SK architect @ Microsoft\n",
    "GitHub @dlucquark — 11/01/2024 6:34\n",
    "\n",
    "here's the fix https://github.com/microsoft/kernel-memory/pull/251 it's merged. However, the service runs with nugets, so it won't see the latest code in main. We need to release the new packages and update the service to use the latest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79cf2a",
   "metadata": {},
   "source": [
    "### Otros comentarios acá:\n",
    "- One drawback of the above approach is that the Semantic Kernel requires data to be indexed only in the MemoryRecord format, which includes fields such as ‘externalSourceName,’ ‘externalId,’ ‘description,’ ‘text,’ etc. Therefore, if you are ingesting data from an external source, you will need to convert the data into the required fields before ingesting it. [link](https://medium.com/@akshaykokane09/step-by-step-guide-to-integrate-azure-cognitives-vector-search-in-your-chatgpt-like-app-part-2-7e32155dbf9e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f0690",
   "metadata": {},
   "source": [
    "# El bypass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108ac8f",
   "metadata": {},
   "source": [
    "En la propia documentaciòn de Microsoft sobre semantic-kernell implementan una consulta sin la clase `memory`. \n",
    "\n",
    "https://techcommunity.microsoft.com/t5/educator-developer-blog/teach-chatgpt-to-answer-questions-using-azure-ai-search-amp/ba-p/3985395 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
